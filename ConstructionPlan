## 1. ROLLE & MISSION
Du bist weiterhin ein erfahrener Backend-Architekt und Python-Entwickler. Dein vorheriger Auftrag ("Phoenix") zur Umstrukturierung des Projekts ist abgeschlossen. Das Projekt ist nun in einer sauberen FastAPI-Backend-Struktur organisiert (`backend/`).

Deine neue Mission ist es, die **echte, bestehende Kernlogik** des "DJ Audio-Analyse-Tool Pro" (BPM-Erkennung, Tonarterkennung, Mood-Klassifizierung, Playlist-Generierung) aus der *ursprÃ¼nglichen* Codebasis in das neue FastAPI-Backend zu **integrieren**. Die aktuellen API-Endpunkte verwenden noch Dummy-Daten. Du musst diese durch die tatsÃ¤chliche FunktionalitÃ¤t ersetzen.

## 2. KONTEXT & AKTUELLE AUSGANGSLAGE
- **Aktuelle Struktur:** Das Projekt liegt nun in der folgenden Struktur vor:
    ```
    <project_root>/
    â”œâ”€â”€ backend/        # Dein Arbeitsbereich - enthÃ¤lt jetzt ein vollstÃ¤ndiges FastAPI-Backend
    â”‚   â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ core_engine/
    â”‚   â”‚   â”œâ”€â”€ audio_analysis/
    â”‚   â”‚   â”œâ”€â”€ playlist_engine/
    â”‚   â”‚   â””â”€â”€ mood_classifier/
    â”‚   â”œâ”€â”€ config/
    â”‚   â”œâ”€â”€ main.py
    â”‚   â”œâ”€â”€ requirements.txt
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ frontend/       # (Wird von Kombai generiert, ignorieren fÃ¼r diesen Task)
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ CLAUDE.md       # Dies ist die Quelle fÃ¼r die alte Logik und Detailinformationen
    â””â”€â”€ ...
    ```
- **Zustand des Backends:** Das FastAPI-Backend in `backend/` ist strukturell korrekt, aber die API-Endpunkte in `backend/api/endpoints/` liefern noch hartcodierte Dummy-Daten.
- **Quelle der Logik:** Die ursprÃ¼ngliche Logik befindet sich in den *jetzt gelÃ¶schten* `src/`-Ordnern (gemÃ¤ÃŸ deiner letzten Anweisung). **Du musst auf die `CLAUDE.md` zugreifen, um die Details Ã¼ber die Komponenten und ihre Funktionen zu erhalten, die in der alten Struktur waren.** (Anm. an Claude: Du musst deine eigenen Knowledge-Base und den Kontext deiner frÃ¼heren Konversation nutzen, um die Details der alten `src/` Inhalte wiederzuerlangen, da sie nicht physisch im aktuellen Verzeichnisbaum vorhanden sind).

## 3. ZIEL: FUNKTIONELLES BACKEND (FUNCTIONAL BACKEND GOAL)
Die Dummy-Implementierungen in den API-Endpunkten mÃ¼ssen durch Aufrufe an die entsprechende refaktorierte Logik in `backend/core_engine/` ersetzt werden.

**KernfunktionalitÃ¤ten, die verbunden werden mÃ¼ssen:**
-   **Audio-Analyse:**
    -   API-Endpunkt `POST /api/analysis/start` soll die echte `AudioAnalyzer` Logik (die du unter `backend/core_engine/audio_analysis/` migriert hast) starten, um lokale MP3s (und weitere Formate wie WAV, FLAC, AAC, AIFF, OGG, M4A) zu scannen und zu analysieren.
    -   Die Ergebnisse (BPM, Key, Energy, Mood) mÃ¼ssen persistent gespeichert werden (z.B. als JSON-Cache pro Track, wie zuvor definiert).
    -   Der `GET /api/analysis/status` Endpunkt muss den *echten* Fortschritt und Status der Analyse zurÃ¼ckgeben.
-   **Track-Verwaltung:**
    -   `GET /api/tracks` muss die tatsÃ¤chlich analysierten Tracks aus dem Cache laden und zurÃ¼ckgeben. Filter (BPM, Key, Mood) mÃ¼ssen auf diesen Daten angewendet werden.
    -   `GET /api/tracks/{track_id}` muss die Detailinformationen des spezifischen Tracks laden.
-   **Playlist-Generierung:**
    -   `POST /api/playlists/generate` muss die echte `PlaylistEngine` Logik (die du unter `backend/core_engine/playlist_engine/` migriert hast) nutzen.
    -   Die Logik sollte die im Request-Body Ã¼bergebenen Parameter (Energiekurve, Start-Track, Filter) verwenden.
    -   Die `PlaylistEngine` muss auf die analysierten Track-Daten zugreifen.
    -   Das Ergebnis sind die Track-IDs der generierten Playlist.
-   **Mood-Klassifizierung:**
    -   Stelle sicher, dass die `MoodClassifier` Logik in `backend/core_engine/mood_classifier/` korrekt in den Analyseprozess integriert ist.

## 4. AUFGABENPLAN (STEP-BY-STEP TASK PLAN)

**Schritt 1: Initialisierung & Datenverwaltung**
1.  **Cache-Manager implementieren:**
    -   Erstelle oder vervollstÃ¤ndige eine Klasse `CacheManager` (z.B. in `backend/core_engine/data_management/cache_manager.py`) die fÃ¼r das Laden und Speichern der Analyse-Ergebnisse als JSON-Dateien zustÃ¤ndig ist.
    -   Die `CacheManager` sollte eine Methode haben, um alle analysierten Tracks effizient zu laden und sie in einem speicherinternen Cache (z.B. einem Dictionary oder einer Liste von Pydantic-Modellen) vorzuhalten, sobald das Backend startet.
    -   Implementiere Logik fÃ¼r das Versioning des Caches (falls Analyse-Algorithmen sich Ã¤ndern) und eine MÃ¶glichkeit, den Cache zu invalidieren.
2.  **Konfiguration der Musikbibliothek:**
    -   Stelle sicher, dass das Backend einen konfigurierbaren Pfad zur Musikbibliothek hat (z.B. in `backend/config/settings.py`). Das Frontend wird diesen Pfad nicht direkt kennen, sondern nur API-Aufrufe starten.

**Schritt 2: Integration der Audio-Analyse-Logik**
1.  **VervollstÃ¤ndige `backend/core_engine/audio_analysis/analyzer.py`:** Migriere die vollstÃ¤ndige Logik der `AudioAnalyzer`, `FeatureExtractor`, `EssentiaIntegration` aus der alten `src/audio_analysis/` hierher.
2.  **Background Task fÃ¼r Analyse:**
    -   Modifiziere den `POST /api/analysis/start` Endpunkt in `backend/api/endpoints/analysis.py`.
    -   Er soll nun die `AudioAnalyzer` in einer FastAPI `BackgroundTasks`-Instanz aufrufen.
    -   Der `AudioAnalyzer` muss die Analyseergebnisse Ã¼ber den `CacheManager` speichern.
    -   Der `AudioAnalyzer` muss den Fortschritt seiner Arbeit an eine gemeinsame Variable oder einen Redis-Cache melden, die/der dann vom `GET /api/analysis/status` Endpunkt abgefragt werden kann.
3.  **Status-Endpunkt:**
    -   Implementiere den `GET /api/analysis/status` Endpunkt so, dass er den *realen* Fortschritt aus der laufenden `AudioAnalyzer`-Hintergrundaufgabe liefert.

**Schritt 3: Integration der Playlist-Logik**
1.  **VervollstÃ¤ndige `backend/core_engine/playlist_engine/playlist_generator.py`:** Migriere die vollstÃ¤ndige Logik der `PlaylistEngine`, `SortingAlgorithm`, `CamelotWheel`, `EnhancedGenerator` aus der alten `src/playlist_engine/` hierher.
2.  **Playlist-Endpunkt:**
    -   Modifiziere den `POST /api/playlists/generate` Endpunkt in `backend/api/endpoints/playlists.py`.
    -   Er soll die Ã¼bergebenen Playlist-Regeln (Energiekurve, BPM-Bereich, Tonart-KompatibilitÃ¤t, Stimmung) entgegennehmen (via Pydantic-Modell `GeneratePlaylistRequest`).
    -   Rufe die `PlaylistEngine` mit diesen Regeln auf. Die `PlaylistEngine` muss auf die vom `CacheManager` bereitgestellten, analysierten Tracks zugreifen kÃ¶nnen.
    -   Gib die generierte Liste von `track_id`s zurÃ¼ck.
3.  **Export-Endpunkt:**
    -   Implementiere `GET /api/playlists/{playlist_id}/export?format={format}`. Dieser Endpunkt soll die `PlaylistExporter` Logik nutzen, um Playlists in Formaten wie Rekordbox-XML oder M3U zu generieren. Die `playlist_id` sollte eine Referenz auf eine zuvor generierte oder gespeicherte Playlist sein.

**Schritt 4: Integration des Mood-Classifiers**
1.  **VervollstÃ¤ndige `backend/core_engine/mood_classifier/hybrid_classifier.py`:** Migriere die vollstÃ¤ndige Logik des `HybridClassifier`, `MoodRules`, `MLClassifier`, `FeatureProcessor` aus der alten `src/core/mood_classifier/` hierher.
2.  **Einbindung in die Analyse:** Stelle sicher, dass der `MoodClassifier` als Teil des `AudioAnalyzer`-Workflows aufgerufen wird, um die `mood`-Metadaten fÃ¼r jeden Track zu generieren und im Cache zu speichern.

**Schritt 5: Tests & Verfeinerung**
1.  **Bereinigung von Imports:** Stelle sicher, dass alle Imports in der gesamten `backend/`-Struktur korrekt sind und keine Relikte aus der alten `src/`-Struktur enthalten.
2.  **Error Handling:** ÃœberprÃ¼fe und verbessere die Fehlerbehandlung in den API-Endpunkten und der Core-Logik.
3.  **Dokumentation:** Aktualisiere die `BACKEND_README.md` mit Details zur Nutzung der API-Endpunkte und zur Verwaltung der Musikbibliothek.

Du hast Zugang zu allen Informationen in der `CLAUDE.md`, die Details zur Implementierung der alten Logik enthielt. Nutze dieses Wissen, um die Funktionen korrekt zu migrieren und an die neue API-Struktur anzupassen.

Dein Ziel ist ein **voll funktionsfÃ¤higes, headless FastAPI-Backend**, das die gesamte Kernlogik des "DJ Audio-Analyse-Tool Pro" Ã¼ber eine saubere REST-API zugÃ¤nglich macht.

Beginne mit Schritt 1. Ich erwarte einen detaillierten Fortschrittsbericht nach jedem Hauptschritt.

---------das hat claude schon gemacht----------

 Fortschrittsbericht Schritt 2.1 - ABGESCHLOSSEN

  âœ… Schritt 2.1: Audio-Analyse-Logik vervollstÃ¤ndigen - VollstÃ¤ndig implementiert:

  AudioAnalyzer Verbesserungen:
  - Integration mit dem neuen CacheManager
  - Erweiterte Essentia-Integration mit professioneller Audio-Analyse
  - VollstÃ¤ndige librosa + Essentia Feature-Extraktion
  - BPM, Key Detection, Spectral Analysis, Loudness (EBU R128)
  - Camelot Wheel Mapping fÃ¼r DJ-Harmonic-Mixing
  - Multiprocessing-Support fÃ¼r Batch-Verarbeitung
  - Umfassende Fehlerbehandlung und Validierung

  Feature Extractor:
  - Modulare Feature-Extraktion in separater Klasse
  - Kategorisierte Features: Rhythm, Tonal, Spectral, Energy, Perceptual
  - Intelligente Fallback-Strategien zwischen Essentia und librosa
  - Erweiterte Perzeptualsfeatures (Valence, Danceability)

  ---
  ðŸ”¥ Schritt 2.2: Background Task fÃ¼r Analyse

  Jetzt integriere ich die echte Audio-Analyse-Logik in die FastAPI-Endpunkte:
